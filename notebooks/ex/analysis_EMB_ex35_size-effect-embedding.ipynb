{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining size effect with Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment description\n",
    "### Narrative set-up\n",
    "Recent results suggest that our current methodology is unable to reproduce the prior results utilizing only degree information (ex33v2.1, see [Reference Figure (1)](#ref-fig-1)). However, this does not rely on embedding information at all and hence, under logistic regression, should be able to reproduce prior \"DC\"-classifier results nearly exactly, up to very minor fluctuations due to random observations. Hence, we find ourselves needing to re-examine the fundamentals of our current workflow's reconstruction.\n",
    "\n",
    "This experiment is a follow-up to EMB_ex34 which established the inconsistency of network size in current experiments and prior work is responsible for the observed performance discrepancies. See [Reference Figure (2)](#ref-fig-2) for an annotated figure illustrating this phenomena.\n",
    "\n",
    "### Goal\n",
    "The main goal of this experiment is to run an \"all features\" version of both our current LogReg-classifier and our previous \"DC\" classifier on the same LFR benchmarks to see if an exactly equivalent experimental setting is able to produce comparable results.\n",
    "\n",
    "This is motivated by the results of EMB_ex34 suggesting that size discrepancies, originally enacted for speed with the slow embedding process, is the primary contributor to current performance discrepancies.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard library ---\n",
    "import sys\n",
    "import pickle\n",
    "from enum import Enum\n",
    "import random\n",
    "\n",
    "# --- Scientific computing ---\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# --- Network science ---\n",
    "from cdlib import algorithms\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "# --- Data handling and visualization ---\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "%matplotlib inline\n",
    "\n",
    "# --- Project source code ---\n",
    "sys.path.append(\"../../src/\")\n",
    "from src.data.preprocessing import duplex_network  # handle overlap, inconsistent node sets\n",
    "from src.data.benchmarks import generate_multiplex_configuration, lfr_multiplex  # benchmark samplers\n",
    "from src.sampling.random import partial_information  # PFI observation\n",
    "from src.classifiers.features import *  # degree feature calculations, label wrapper\n",
    "from src.classifiers.logreg import *  # wrappers for scikit-learn logistic regression model functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Pathing aliases\n",
    "_ROOT = \"../../\"\n",
    "_DATA = _ROOT + \"data/input/\"\n",
    "_DFS = _ROOT + \"results/dataframes/\"\n",
    "_FIGS = _ROOT + \"results/plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Plotting parameters\n",
    "custom_plot_settings = {\n",
    "    # Figure config\n",
    "    \"figure.figsize\": (8,6),\n",
    "    \"figure.frameon\": True,\n",
    "    \"figure.autolayout\": True,\n",
    "    \"axes.titlesize\": 16,\n",
    "    # Axes config\n",
    "    \"xtick.minor.size\": 2,\n",
    "    # Save-to-disk config\n",
    "    \"savefig.facecolor\": \"white\",\n",
    "    \"savefig.transparent\": False\n",
    "}\n",
    "mpl.rcParams.update(custom_plot_settings)\n",
    "\n",
    "# * Plotting aliases\n",
    "colors_ = [\"black\", \"red\", \"blue\", \"green\"]\n",
    "markers_ = [\"o\", \"s\", \"+\", \"^\"]\n",
    "viridis_ = mpl.colormaps['viridis']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_finder (G):\n",
    "    # >>> Book-keeping >>>\n",
    "    sigma = {}\n",
    "    c = 0\n",
    "\n",
    "    # <<< Book-keeping <<<\n",
    "\n",
    "    # >>> Community detection >>>\n",
    "    # Apply community detection to network\n",
    "    C = algorithms.louvain(G)\n",
    "\n",
    "    # Form node -> community_id mapping\n",
    "    for r in C.communities:\n",
    "        for q in r:\n",
    "            sigma[q] = c\n",
    "        c = c + 1\n",
    "\n",
    "    # Estimate community strength\n",
    "    mu = tot = 0.0\n",
    "    for n in G.nodes():\n",
    "        for m in G.neighbors(n):\n",
    "            tot += 1.0\n",
    "            if sigma[n] == sigma[m]:\n",
    "                mu += 1.0\n",
    "    # <<< Community detection <<<\n",
    "\n",
    "    return sigma, mu, tot\n",
    "\n",
    "def classifier (rem_G1, rem_G2, Etest, TT = 0, show_log = False):\n",
    "         # >>> DC Classifier >>>\n",
    "    if TT == 0:\n",
    "        sigma1, mu1, tot1 = community_finder(rem_G1)\n",
    "        sigma2, mu2, tot2 = community_finder(rem_G2)\n",
    "\n",
    "\n",
    "        mu = 0.5\n",
    "        if tot1 + tot2 > 0.0:\n",
    "            mu = (mu1 + mu2) / (tot1 + tot2)\n",
    "\n",
    "        classification, scores, ground_truth = [], [], []\n",
    "\n",
    "        for e in Etest:\n",
    "            n = e[0]\n",
    "            m = e[1]\n",
    "\n",
    "            s1 = rem_G1.degree(n)*rem_G1.degree(m)\n",
    "            if sigma1[n] == sigma1[m]:\n",
    "                s1 = s1 * mu\n",
    "            else:\n",
    "                s1 = s1 * (1.0-mu)\n",
    "\n",
    "            s2 = rem_G2.degree(n)*rem_G2.degree(m)\n",
    "            if sigma2[n] == sigma2[m]:\n",
    "                s2 = s2 * mu\n",
    "            else:\n",
    "                s2 = s2 * (1.0-mu)\n",
    "\n",
    "            t1 = t2 = 0.5\n",
    "            if s1 + s2 > 0.0:\n",
    "                t1 = s1 / (s1 + s2)\n",
    "                t2 = s2 / (s1 + s2)\n",
    "\n",
    "            s = random.randint(0,1)\n",
    "            if t1 > t2:\n",
    "                s = 1\n",
    "            if t2 > t1:\n",
    "                s = 0\n",
    "\n",
    "            if show_log == True:\n",
    "                print (mu)\n",
    "                print (rem_G1.degree(n), rem_G1.degree(m), t1)\n",
    "                print (rem_G2.degree(n), rem_G2.degree(m), t2)\n",
    "                print (Etest[e], '\\n')\n",
    "\n",
    "            scores.append(t1)\n",
    "            classification.append(s)\n",
    "            ground_truth.append(Etest[e])\n",
    "\n",
    "        return classification, scores, ground_truth\n",
    "    # <<< DC Classifier <<<\n",
    "\n",
    "\n",
    "    # >>> D Classifier >>>\n",
    "    if TT == 1:\n",
    "        classification, scores, ground_truth = [], [], []\n",
    "\n",
    "        for e in Etest:\n",
    "            n = e[0]\n",
    "            m = e[1]\n",
    "\n",
    "            s1 = rem_G1.degree(n)*rem_G1.degree(m)\n",
    "            s2 = rem_G2.degree(n)*rem_G2.degree(m)\n",
    "\n",
    "            t1 = t2 = 0.5\n",
    "            if s1 + s2 > 0.0:\n",
    "                t1 = s1 / (s1 + s2)\n",
    "                t2 = s2 / (s1 + s2)\n",
    "\n",
    "            s = random.randint(0,1)\n",
    "            if t1 > t2:\n",
    "                s = 1\n",
    "            if t2 > t1:\n",
    "                s = 0\n",
    "\n",
    "            scores.append(t1)\n",
    "            classification.append(s)\n",
    "            ground_truth.append(Etest[e])\n",
    "\n",
    "        return classification, scores, ground_truth\n",
    "    # <<< D Classifier <<<\n",
    "\n",
    "def perform_analysis (G1, G2, step, TT = 0):\n",
    "\n",
    "    # >>> Book-keeping >>>\n",
    "    x , y, z  = [], [], []\n",
    "    frac = 0.0\n",
    "    # <<< Book-keeping <<<\n",
    "\n",
    "    # >>> Sweep over relative size of training set >>>\n",
    "    while frac < 1.0:\n",
    "        if frac <= 1.0 - step:\n",
    "            print ('# %.2f ' %frac, ' %.2f' %(1.0 - step))\n",
    "\n",
    "            # Observe information\n",
    "            rem_G1, rem_G2, Etest, Etrain  = partial_information (G1, G2, frac)\n",
    "\n",
    "            # Reconstruct multiplex\n",
    "            classification, scores, ground_truth = classifier (rem_G1, rem_G2, Etest, TT)\n",
    "\n",
    "            # Measure reconstruction performance\n",
    "            acc = accuracy_score(ground_truth, classification)\n",
    "            auc = roc_auc_score(ground_truth, scores)\n",
    "\n",
    "            x.append(frac)\n",
    "            y.append(acc)\n",
    "            z.append(auc)\n",
    "\n",
    "        frac += step\n",
    "    # <<< Sweep over relative size of training set <<<\n",
    "\n",
    "    results = [x, y, z]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalize_embedding_per_component (G, n2v_emb):\n",
    "    n2v_emb_rescaled = {}\n",
    "    for n in G:\n",
    "        n2v_emb_rescaled[n] = n2v_emb.wv[str(n)]\n",
    "\n",
    "    nr_comp = 0\n",
    "    components = nx.connected_components(G)\n",
    "    for c in components:\n",
    "        nr_comp += 1\n",
    "        list_of_nodes = []\n",
    "        norm = 0.0\n",
    "        for n in c:\n",
    "            list_of_nodes.append(n2v_emb_rescaled[n])\n",
    "        cm = np.add.reduce(list_of_nodes) / float(len(list_of_nodes))\n",
    "        for n in c:\n",
    "            n2v_emb_rescaled[n] = n2v_emb_rescaled[n] - cm\n",
    "            norm += np.linalg.norm(n2v_emb_rescaled[n])\n",
    "        if norm > 0.0:\n",
    "            for n in c:\n",
    "                n2v_emb_rescaled[n] = n2v_emb_rescaled[n] / norm\n",
    "\n",
    "    return n2v_emb_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_classifier (Etest, rem_G1, emb_rescaled_1, rem_G2, emb_rescaled_2, log_regression, penalty, option):\n",
    "\n",
    "#     print('#Intercept = ', log_regression.intercept_[0])\n",
    "#     print('#Degree coefficient = ', log_regression.coef_[0][0])\n",
    "#     print('#Embedding coefficient = ', log_regression.coef_[0][1])\n",
    "\n",
    "    classification, scores, ground_truth = [], [], []\n",
    "\n",
    "\n",
    "\n",
    "    for e in Etest:\n",
    "        n = e[0]\n",
    "        m = e[1]\n",
    "\n",
    "\n",
    "        ##degree\n",
    "        s1 = rem_G1.degree(n)*rem_G1.degree(m)\n",
    "        s2 = rem_G2.degree(n)*rem_G2.degree(m)\n",
    "\n",
    "        t1 = t2 = 0.5\n",
    "        if s1 + s2 > 0.0:\n",
    "            t1 = s1 / (s1 + s2)\n",
    "            t2 = s2 / (s1 + s2)\n",
    "        t1 = 2.0*t1-1.0\n",
    "        t2 = 2.0*t2-1.0\n",
    "        ##embedding\n",
    "\n",
    "        es1 = 1.0/(np.linalg.norm(emb_rescaled_1[n] - emb_rescaled_1[m]) + penalty)\n",
    "        es2 = 1.0/(np.linalg.norm(emb_rescaled_2[n] - emb_rescaled_2[m]) + penalty)\n",
    "\n",
    "        et1 = et2 = 0.5\n",
    "        if es1 + es2 > 0.0:\n",
    "            et1 = es1 / (es1 + es2)\n",
    "            et2 = es2 / (es1 + es2)\n",
    "        et1 = 2.0*et1-1.0\n",
    "        et2 = 2.0*et2-1.0\n",
    "        ###########\n",
    "\n",
    "\n",
    "        if option == 1:\n",
    "#             print ('# option 1 , degree only')\n",
    "            prob1 = log_regression.coef_[0][0] * t1\n",
    "            prob1 = 1.0 / (1.0 + np.exp(-prob1))\n",
    "            prob2 = 1.0 - prob1\n",
    "\n",
    "        if option == 2:\n",
    "#             print ('# option 2 , degree + intercept')\n",
    "            prob1 = log_regression.intercept_[0] + log_regression.coef_[0][0] * t1\n",
    "            prob1 = 1.0 / (1.0 + np.exp(-prob1))\n",
    "            prob2 = 1.0 - prob1\n",
    "\n",
    "        if option == 3:\n",
    "#             print ('# option 3 , embedding only')\n",
    "            prob1 = log_regression.coef_[0][0] * et1\n",
    "            prob1 = 1.0 / (1.0 + np.exp(-prob1))\n",
    "            prob2 = 1.0 - prob1\n",
    "\n",
    "        if option == 4:\n",
    "#             print ('# option 4 , embedding + intercept')\n",
    "            prob1 = log_regression.intercept_[0] + log_regression.coef_[0][0] * et1\n",
    "            prob1 = 1.0 / (1.0 + np.exp(-prob1))\n",
    "            prob2 = 1.0 - prob1\n",
    "\n",
    "        if option == 5:\n",
    "#             print ('# option 5 , degree + embedding')\n",
    "            prob1 = log_regression.coef_[0][0] * t1 + log_regression.coef_[0][1] * et1\n",
    "            prob1 = 1.0 / (1.0 + np.exp(-prob1))\n",
    "            prob2 = 1.0 - prob1\n",
    "\n",
    "        if option == 6:\n",
    "#             print ('# option 6 , degree + embedding + intercept')\n",
    "            prob1 = log_regression.intercept_[0] + log_regression.coef_[0][0] * t1 + log_regression.coef_[0][1] * et1\n",
    "            prob1 = 1.0 / (1.0 + np.exp(-prob1))\n",
    "            prob2 = 1.0 - prob1\n",
    "\n",
    "\n",
    "\n",
    "        s = random.randint(0,1)\n",
    "        if prob1 > prob2:\n",
    "            s = 1\n",
    "        if prob2 > prob1:\n",
    "            s = 0\n",
    "\n",
    "\n",
    "\n",
    "        scores.append(prob1)\n",
    "        classification.append(s)\n",
    "        ground_truth.append(Etest[e])\n",
    "\n",
    "\n",
    "\n",
    "    return classification, scores, ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_edges_training (rem_G1, emb_rescaled_1, rem_G2, emb_rescaled_2, penalty):\n",
    "\n",
    "\n",
    "    ####################################\n",
    "    degree_score = {}\n",
    "    emb_score = {}\n",
    "    ground_truth = {}\n",
    "\n",
    "    for e in rem_G1.edges():\n",
    "\n",
    "        n = e[0]\n",
    "        m = e[1]\n",
    "\n",
    "        tmp1 = rem_G1.degree(n)*rem_G1.degree(m)\n",
    "        tmp2 = rem_G2.degree(n)*rem_G2.degree(m)\n",
    "\n",
    "        stmp1 = 1.0/(np.linalg.norm(emb_rescaled_1[n] - emb_rescaled_1[m]) + penalty)\n",
    "        stmp2 = 1.0/(np.linalg.norm(emb_rescaled_2[n] - emb_rescaled_2[m]) + penalty)\n",
    "\n",
    "        if n < m:\n",
    "            degree_score[n,m] = tmp1/(tmp1+tmp2)\n",
    "            emb_score[n,m] = stmp1/(stmp1+stmp2)\n",
    "            ground_truth[n,m] = 1\n",
    "        else:\n",
    "            degree_score[m,n] = tmp1/(tmp1+tmp2)\n",
    "            emb_score[m,n] = stmp1/(stmp1+stmp2)\n",
    "            ground_truth[m,n] = 1\n",
    "\n",
    "\n",
    "    for e in rem_G2.edges():\n",
    "\n",
    "        n = e[0]\n",
    "        m = e[1]\n",
    "\n",
    "        tmp1 = rem_G1.degree(n)*rem_G1.degree(m)\n",
    "        tmp2 = rem_G2.degree(n)*rem_G2.degree(m)\n",
    "\n",
    "        stmp1 = 1.0/(np.linalg.norm(emb_rescaled_1[n] - emb_rescaled_1[m]) + penalty)\n",
    "        stmp2 = 1.0/(np.linalg.norm(emb_rescaled_2[n] - emb_rescaled_2[m]) + penalty)\n",
    "\n",
    "        if n < m:\n",
    "            degree_score[n,m] = tmp1/(tmp1+tmp2)\n",
    "            emb_score[n,m] = stmp1/(stmp1+stmp2)\n",
    "            ground_truth[n,m] = 0\n",
    "        else:\n",
    "            degree_score[m,n] = tmp1/(tmp1+tmp2)\n",
    "            emb_score[m,n] = stmp1/(stmp1+stmp2)\n",
    "            ground_truth[m,n] = 0\n",
    "    ###########################\n",
    "\n",
    "#     for e in degree_score:\n",
    "#         print (e, degree_score[e], emb_score[e], ground_truth[e])\n",
    "\n",
    "    return degree_score, emb_score, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logisitic_regression (degree_score, emb_score, ground_truth, option):\n",
    "\n",
    "    list_of_edges = list(degree_score.keys())\n",
    "\n",
    "    #degree only\n",
    "    if option == 1 or option == 2:\n",
    "\n",
    "        X = np.zeros((len(list_of_edges),1))\n",
    "        y = np.zeros(len(list_of_edges))\n",
    "\n",
    "        for i in range(0,len(list_of_edges)):\n",
    "            X[i][0] = 2.0*degree_score[list_of_edges[i]]-1.0\n",
    "            y[i] = ground_truth[list_of_edges[i]]\n",
    "\n",
    "        if option == 1:\n",
    "            print ('# option 1 , degree only')\n",
    "            log_regression = LogisticRegression(fit_intercept=False, penalty='none').fit(X, y)\n",
    "            print('#Training set score ', log_regression.score(X, y))\n",
    "            print('#Degree coefficient = ', log_regression.coef_[0][0])\n",
    "\n",
    "        if option == 2:\n",
    "            print ('# option 2 , degree + intercept')\n",
    "            log_regression = LogisticRegression(fit_intercept=True, penalty='none').fit(X, y)\n",
    "            print('#Training set score ', log_regression.score(X, y))\n",
    "            print('#Intercept = ', log_regression.intercept_[0])\n",
    "            print('#Degree coefficient = ', log_regression.coef_[0][0])\n",
    "\n",
    "        return log_regression\n",
    "\n",
    "\n",
    "\n",
    "    #embedding only\n",
    "    if option == 3 or option == 4:\n",
    "\n",
    "        X = np.zeros((len(list_of_edges),1))\n",
    "        y = np.zeros(len(list_of_edges))\n",
    "\n",
    "        for i in range(0,len(list_of_edges)):\n",
    "            X[i][0] = 2.0*emb_score[list_of_edges[i]]-1.0\n",
    "            y[i] = ground_truth[list_of_edges[i]]\n",
    "\n",
    "        if option == 3:\n",
    "            print ('# option 3 , embedding only')\n",
    "            log_regression = LogisticRegression(fit_intercept=False, penalty='none').fit(X, y)\n",
    "            print('#Training set score ', log_regression.score(X, y))\n",
    "            print('#Embedding coefficient = ', log_regression.coef_[0][0])\n",
    "\n",
    "        if option == 4:\n",
    "            print ('# option 4 , embedding + intercept')\n",
    "            log_regression = LogisticRegression(fit_intercept=True,  penalty='none').fit(X, y)\n",
    "            print('#Training set score ', log_regression.score(X, y))\n",
    "            print('#Intercept = ', log_regression.intercept_[0])\n",
    "            print('#Embedding coefficient = ', log_regression.coef_[0][0])\n",
    "\n",
    "        return log_regression\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if option == 5 or option == 6:\n",
    "\n",
    "        X = np.zeros((len(list_of_edges),2))\n",
    "        y = np.zeros(len(list_of_edges))\n",
    "\n",
    "        for i in range(0,len(list_of_edges)):\n",
    "            X[i][0] = 2.0*degree_score[list_of_edges[i]]-1.0\n",
    "            X[i][1] = 2.0*emb_score[list_of_edges[i]]-1.0\n",
    "            y[i] = ground_truth[list_of_edges[i]]\n",
    "\n",
    "        if option == 5:\n",
    "            print ('# option 5 , degree + embedding')\n",
    "            log_regression = LogisticRegression(fit_intercept=False,  penalty='none').fit(X, y)\n",
    "            print('#Training set score ', log_regression.score(X, y))\n",
    "            print('#Degree coefficient = ', log_regression.coef_[0][0])\n",
    "            print('#Embedding coefficient = ', log_regression.coef_[0][1])\n",
    "\n",
    "        if option == 6:\n",
    "            log_regression = LogisticRegression(fit_intercept=True, penalty='none').fit(X, y)\n",
    "            print('#Training set score ', log_regression.score(X, y))\n",
    "            print('#Intercept = ', log_regression.intercept_[0])\n",
    "            print('#Degree coefficient = ', log_regression.coef_[0][0])\n",
    "            print('#Embedding coefficient = ', log_regression.coef_[0][1])\n",
    "\n",
    "        return log_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_analysis_embedding (G1, G2, step, option = 1, penalty = 0.1):\n",
    "\n",
    "\n",
    "\n",
    "    x , y, z  = [], [], []\n",
    "\n",
    "\n",
    "    frac = step\n",
    "    while frac < 1.0:\n",
    "\n",
    "        if frac <= 1.0 - step:\n",
    "\n",
    "            print('\\n\\nFrac ', frac)\n",
    "\n",
    "            rem_G1, rem_G2, Etest, Etrain  = partial_information (G1, G2, frac)\n",
    "\n",
    "            node2vec1 = Node2Vec(rem_G1, dimensions=62, walk_length=20, num_walks=10, workers=16)\n",
    "            node2vec2 = Node2Vec(rem_G2, dimensions=64, walk_length=20, num_walks=10, workers=16)\n",
    "\n",
    "            model1 = node2vec1.fit(window=10, min_count=1, batch_words=4)\n",
    "            model2 = node2vec2.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "            n2v_emb_rescaled_1 = renormalize_embedding_per_component (rem_G1, model1)\n",
    "            n2v_emb_rescaled_2 = renormalize_embedding_per_component (rem_G2, model2)\n",
    "\n",
    "            degree_score, emb_score, ground_truth = score_edges_training (rem_G1, n2v_emb_rescaled_1, rem_G2, n2v_emb_rescaled_2, penalty)\n",
    "\n",
    "\n",
    "            log_regression = perform_logisitic_regression (degree_score, emb_score, ground_truth, option)\n",
    "\n",
    "            classification, scores, ground_truth = embedding_classifier (Etest, rem_G1, n2v_emb_rescaled_1, rem_G2, n2v_emb_rescaled_2, log_regression, penalty, option)\n",
    "\n",
    "            acc = accuracy_score(ground_truth, classification)\n",
    "            auc = roc_auc_score(ground_truth, scores)\n",
    "\n",
    "\n",
    "\n",
    "            x.append(frac)\n",
    "            y.append(acc)\n",
    "            z.append(auc)\n",
    "\n",
    "\n",
    "        frac += step\n",
    "\n",
    "\n",
    "    results = [x, y, z]\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set-up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DATA_DICT = {\n",
    "    \"N\": \"number of nodes (in shared node set)\",\n",
    "    \"GAMMA\": \"degree exponent of power-law degree distribution (from sampled distribution, finite sampling effects may yield different exponent if re-fit)\",\n",
    "    \"MU\": \"mixing parameter for LFR model. Smaller MU implies (and is implied by) stronger modular structure.\",\n",
    "    \"KMIN\": \"minimum degree (in either layer)\",\n",
    "    \"KMAX\": \"maximum degree (in either layer)\",\n",
    "    \"AVG_K\": \"average degree (in both layers)\",\n",
    "    \"T1\": \"equivalent to GAMMA for LFR models\",\n",
    "    \"T2\": \"community size power-law distribution exponent\",\n",
    "    \"PROB\": \"relabeling probability. Controls correlation, with 0->1 = correlated->uncorrelated\",\n",
    "    \"SIGN\": \"degree sequence sorting. Couples with PROB to produce anti/directly correlated degree sequences. -1 => anticorrelated, 1 => correlated\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkParams(Enum):\n",
    "    # Shared params\n",
    "    N = 1_000\n",
    "    PROB = 1.0\n",
    "    GAMMA = 2.1\n",
    "    KMAX = np.sqrt(1_000)\n",
    "    # Configuration model params\n",
    "    KMIN = 3\n",
    "    SIGN = 1\n",
    "    # LFR params\n",
    "    AVG_K = 6.0\n",
    "    T2 = 1.0\n",
    "    MU = 0.1\n",
    "    MIN_COMMUNITY = 1 # ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentParams(Enum):\n",
    "    THETAS = np.linspace(0.05, 0.95, 10, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGREG = {\"fit_intercept\": True, \"solver\": \"newton-cholesky\", \"penalty\": None}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample duplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting... -N 1000\n",
      "setting... -k 6.0\n",
      "setting... -maxk 31.622776601683793\n",
      "setting... -t1 2.1\n",
      "setting... -t2 1.0\n",
      "setting... -mu 0.1\n",
      "\n",
      "**************************************************************\n",
      "number of nodes:\t1000\n",
      "average degree:\t6\n",
      "maximum degree:\t32\n",
      "exponent for the degree distribution:\t2.1\n",
      "exponent for the community size distribution:\t1\n",
      "mixing parameter:\t0.1\n",
      "number of overlapping nodes:\t0\n",
      "number of memberships of the overlapping nodes:\t0\n",
      "**************************************************************\n",
      "\n",
      "-----------------------------------------------------------\n",
      "community size range automatically set equal to [3 , 32]\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "6 4 6 17 6 18 32 20 7 7 5 23 3 20 4 6 3 6 3 5 5 5 7 5 3 7 13 6 22 6 19 6 11 9 5 8 3 17 11 5 16 11 4 5 5 7 3 18 10 6 5 10 27 6 30 15 10 4 5 9 5 9 8 17 5 3 3 10 19 22 7 21 13 13 5 6 4 8 3 8 20 5 4 6 7 4 8 6 18 28 12 8 28 11 4 9 5 18 30 \n",
      "\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "4 6 17 6 18 32 20 7 7 5 23 3 20 4 6 3 6 3 5 5 5 7 5 3 7 13 6 22 6 19 6 11 9 5 8 3 17 11 5 16 11 4 5 5 7 3 18 10 6 5 10 27 6 30 15 10 4 5 9 5 9 8 17 5 3 3 10 19 22 7 21 13 13 5 6 4 8 7 8 20 5 4 6 7 4 8 6 18 28 12 8 28 11 6 9 5 18 30 \n",
      "\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "6 17 6 18 32 20 7 7 5 23 3 20 4 6 3 6 3 5 5 5 7 5 3 7 13 6 22 6 19 6 11 9 5 8 3 17 11 5 16 11 4 5 5 7 3 18 10 6 5 10 27 6 30 15 10 4 5 9 5 9 8 17 5 3 7 10 19 22 7 21 13 13 5 6 4 8 7 8 20 5 4 6 7 4 8 6 18 28 12 8 28 11 6 9 5 18 30 \n",
      "\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "17 6 18 32 20 7 7 5 23 3 20 4 6 3 6 3 5 5 5 7 5 3 7 13 6 22 6 19 6 11 9 5 8 3 17 11 5 16 11 4 5 5 7 3 18 10 6 5 10 27 6 30 15 10 4 5 9 5 9 8 17 5 7 7 10 19 22 7 21 13 13 5 6 4 8 7 8 20 5 4 6 7 6 8 6 18 28 12 8 28 11 6 9 5 18 30 \n",
      "\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "6 18 32 20 7 7 5 23 3 20 4 6 3 6 3 5 5 5 7 5 3 7 13 6 22 6 19 6 11 9 5 8 3 17 11 5 16 11 4 5 5 7 7 18 10 6 5 10 27 6 30 15 10 4 5 9 5 9 8 17 5 7 7 10 19 22 7 21 13 13 5 6 4 8 7 8 20 5 17 6 7 6 8 6 18 28 12 8 28 11 6 9 5 18 30 \n",
      "\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "18 32 20 7 7 5 23 3 20 4 6 3 6 3 5 5 5 7 5 3 7 13 6 22 6 19 6 11 9 5 8 7 17 11 5 16 11 4 5 5 7 7 18 10 6 5 10 27 6 30 15 10 4 5 9 5 9 8 17 5 7 7 10 19 22 7 21 13 13 5 6 6 8 7 8 20 5 17 6 7 6 8 6 18 28 12 8 28 11 6 9 5 18 30 \n",
      "\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "32 20 7 7 5 23 3 20 4 6 3 6 3 5 5 5 7 5 7 7 13 6 22 6 19 6 11 9 5 8 7 17 11 5 16 11 4 5 5 7 7 18 10 6 5 10 27 6 30 15 10 18 5 9 5 9 8 17 5 7 7 10 19 22 7 21 13 13 5 6 6 8 7 8 20 5 17 6 7 6 8 6 18 28 12 8 28 11 6 9 5 18 30 \n",
      "\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "20 7 7 5 23 3 20 4 6 3 6 7 5 5 5 7 5 7 7 13 6 22 6 19 6 11 9 5 8 7 17 11 5 16 11 32 5 5 7 7 18 10 6 5 10 27 6 30 15 10 18 5 9 5 9 8 17 5 7 7 10 19 22 7 21 13 13 5 6 6 8 7 8 20 5 17 6 7 6 8 6 18 28 12 8 28 11 6 9 5 18 30 \n",
      "\n",
      "it took too long to decide the memberships; I will try to change the community sizes\n",
      "new community sizes\n",
      "7 7 5 23 3 20 20 6 7 6 7 5 5 5 7 5 7 7 13 6 22 6 19 6 11 9 5 8 7 17 11 5 16 11 32 5 5 7 7 18 10 6 5 10 27 6 30 15 10 18 5 9 5 9 8 17 5 7 7 10 19 22 7 21 13 13 5 6 6 8 7 8 20 5 17 6 7 6 8 6 18 28 12 8 28 11 6 9 5 18 30 \n",
      "\n",
      "building communities... \n",
      "connecting communities... \n",
      "recording network...\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "network of 1000 vertices and 3380 edges;\t average degree = 6.76\n",
      "\n",
      "average mixing parameter: 0.103428 +/- 0.116067\n",
      "p_in: 0.564899\tp_out: 0.000576793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation fault\n"
     ]
    }
   ],
   "source": [
    "duplex, _, _, _ = lfr_multiplex(\n",
    "    int(NetworkParams.N.value),  # number of nodes\n",
    "    NetworkParams.GAMMA.value,  # degree distribution exponent\n",
    "    NetworkParams.T2.value,  # community size distribution exponent\n",
    "    NetworkParams.MU.value,  # community mixing parameter\n",
    "    NetworkParams.AVG_K.value,  # average degree\n",
    "    NetworkParams.KMAX.value,  # maximum degree\n",
    "    NetworkParams.MIN_COMMUNITY.value,  # minimum community size (ignored)\n",
    "    NetworkParams.PROB.value,  # degree sequence correlation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common edges removed: 24\n",
      "Number of inactive nodes removed from layer 1: 0\n",
      "Number of inactive nodes removed from layer 2: 0\n",
      "Size of active node set union from layers 1 and 2: 2000\n"
     ]
    }
   ],
   "source": [
    "G, H = duplex_network(duplex, 1, 2, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute remnants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "remnants = dict()  # theta -> [remnants infomation] mapping\n",
    "for theta in ExperimentParams.THETAS.value:\n",
    "    remnant_G, remnant_H, test_edges, train_edges = partial_information(G, H, theta)\n",
    "    record = {\n",
    "        \"remnants\": (remnant_G, remnant_H),\n",
    "        \"observed_edges\": train_edges,\n",
    "        \"unobserved_edges\": test_edges\n",
    "    }\n",
    "    remnants[theta] = record"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()  # theta -> [train features, test features]\n",
    "labels = dict()  # theta -> [train labels, test labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 1904.41it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2168.29it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2207.78it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2198.38it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2427.82it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2354.89it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2555.34it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2579.42it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2935.52it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 2781.96it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 3230.11it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 3155.13it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 3496.67it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 3447.43it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 3757.93it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 3835.80it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 4433.23it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 3578.35it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 4781.52it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Computing transition probabilities: 100%|██████████| 1000/1000 [00:00<00:00, 4749.45it/s]\n",
      "Generating walks (CPU: 11): 0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 12): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 13): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 14): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 15): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Generating walks (CPU: 16): 0it [00:00, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "Generating walks (CPU: 5): 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "Generating walks (CPU: 6): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 8): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Generating walks (CPU: 9): 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Generating walks (CPU: 10): 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "for theta, record in remnants.items():\n",
    "    # --- Degree feature ---\n",
    "    # Partially compute degree likelihood feature\n",
    "    src_degrees_train, tgt_degrees_train = get_degrees(record[\"remnants\"], list(record[\"observed_edges\"].keys()))\n",
    "    src_degrees_test, tgt_degrees_test = get_degrees(record[\"remnants\"], list(record[\"unobserved_edges\"].keys()))\n",
    "\n",
    "    # Complete degree likelihood feature calculations\n",
    "    feature_degrees_train = get_configuration_probabilities_feature(src_degrees_train, tgt_degrees_train)\n",
    "    feature_degrees_test = get_configuration_probabilities_feature(src_degrees_test, tgt_degrees_test)\n",
    "\n",
    "    # --- Embedding feature ---\n",
    "    # & Embed remnants\n",
    "    node2vec1 = Node2Vec(record[\"remnants\"][0], dimensions=128, walk_length=50, num_walks=10, workers=16)\n",
    "    node2vec2 = Node2Vec(record[\"remnants\"][1], dimensions=128, walk_length=50, num_walks=10, workers=16)\n",
    "\n",
    "    model1 = node2vec1.fit(window=10, min_count=1, batch_words=4)\n",
    "    model2 = node2vec2.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "    # & Align centers\n",
    "    embeddings_G = renormalize_embedding_per_component(record[\"remnants\"][0], model1)\n",
    "    embeddings_H = renormalize_embedding_per_component(record[\"remnants\"][1], model2)\n",
    "\n",
    "    distances_G_train, distances_H_train = \\\n",
    "        get_distances((embeddings_G, embeddings_H), list(record[\"observed_edges\"].keys()))\n",
    "    distances_G_test, distances_H_test = \\\n",
    "        get_distances((embeddings_G, embeddings_H), list(record[\"unobserved_edges\"].keys()))\n",
    "\n",
    "    feature_distances_train = get_configuration_distances_feature(distances_G_train, distances_H_train, zde_penalty=0.1)\n",
    "    feature_distances_test = get_configuration_distances_feature(distances_G_test, distances_H_test, zde_penalty=0.1)\n",
    "\n",
    "    normalizer = max(\n",
    "        np.abs(min(feature_distances_train)),\n",
    "        np.abs(max(feature_distances_train)),\n",
    "    )\n",
    "    feature_distances_train = [x / normalizer for x in feature_distances_train]\n",
    "\n",
    "    normalizer = max(\n",
    "        np.abs(min(feature_distances_test)),\n",
    "        np.abs(max(feature_distances_test)),\n",
    "    )\n",
    "    feature_distances_test = [x / normalizer for x in feature_distances_test]\n",
    "\n",
    "    # --- Cleaning up features ---\n",
    "    feature_matrix_train, feature_matrix_test = \\\n",
    "        format_feature_matrix(\n",
    "            {\"emb\", \"imb\", \"deg\"},\n",
    "            len(record[\"observed_edges\"]), len(record[\"unobserved_edges\"]),\n",
    "            feature_distances_train, feature_distances_test,\n",
    "            feature_degrees_train, feature_degrees_test\n",
    "        )\n",
    "\n",
    "    # --- Labels ---\n",
    "    labels_train, labels_test = get_labels(record[\"observed_edges\"], record[\"unobserved_edges\"])\n",
    "\n",
    "    # Save to feature and label mappings\n",
    "    features[theta] = (feature_matrix_train, feature_matrix_test)\n",
    "    labels[theta] = (labels_train, labels_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()  # theta -> [trained logistic regression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theta in ExperimentParams.THETAS.value:\n",
    "    # Retrieve training labels\n",
    "    Y = labels[theta][0]\n",
    "\n",
    "    # Retrieve training features\n",
    "    X = features[theta][0]\n",
    "\n",
    "    # Format training features for scikit-learn models\n",
    "    # X = np.array(X).reshape(-1,1)\n",
    "\n",
    "    # Train model\n",
    "    model = train_fit_logreg(X, Y, LOGREG)\n",
    "\n",
    "    # Save to models mapping\n",
    "    models[theta] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performances = dict()  # theta -> [performances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theta in ExperimentParams.THETAS.value:\n",
    "    # Retrieve testing labels\n",
    "    Y = labels[theta][1]\n",
    "\n",
    "    # Retrieve testing features\n",
    "    X = features[theta][1]\n",
    "\n",
    "    # Format testing features for scikit-learn models\n",
    "    # X = np.array(X).reshape(-1,1)\n",
    "\n",
    "    # Apply model to test data\n",
    "    model = models[theta]\n",
    "    accuracy = get_model_accuracy(model, X, Y)\n",
    "    auroc = get_model_auroc(model, X, Y)\n",
    "    aupr = get_model_aupr(model, X, Y)\n",
    "    performances = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"auroc\": auroc,\n",
    "        \"aupr\": aupr,\n",
    "    }\n",
    "\n",
    "    # Save to models mapping\n",
    "    model_performances[theta] = performances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogReg-FR reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = 'node2vec'\n",
    "# penalty = 0.01\n",
    "# option = 6\n",
    "# tmp = {}\n",
    "# T = 1\n",
    "# l1 = 1\n",
    "# l2 = 2\n",
    "# results_FR = {}\n",
    "\n",
    "\n",
    "# for t in range(T):\n",
    "#     tmp[t] = perform_analysis_embedding (G, H, 0.1, option, penalty)\n",
    "\n",
    "# results_FR[method, l1, l2] = np.zeros((3,len(tmp[0][0])))\n",
    "# for t in tmp:\n",
    "#     for q in range(len(tmp[t][0])):\n",
    "#         results_FR[method, l1, l2][0,q] += tmp[t][0][q]/float(T)\n",
    "#         results_FR[method, l1, l2][1,q] += tmp[t][1][q]/float(T)\n",
    "#         results_FR[method, l1, l2][2,q] += tmp[t][2][q]/float(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = 'node2vec'\n",
    "# penalty = 0.01\n",
    "# option = 4\n",
    "# tmp = {}\n",
    "# T = 1\n",
    "# l1 = 1\n",
    "# l2 = 2\n",
    "# results_FR_nodeg = {}\n",
    "\n",
    "\n",
    "# for t in range(T):\n",
    "#     tmp[t] = perform_analysis_embedding (G, H, 0.1, option, penalty)\n",
    "\n",
    "# results_FR_nodeg[method, l1, l2] = np.zeros((3,len(tmp[0][0])))\n",
    "# for t in tmp:\n",
    "#     for q in range(len(tmp[t][0])):\n",
    "#         results_FR_nodeg[method, l1, l2][0,q] += tmp[t][0][q]/float(T)\n",
    "#         results_FR_nodeg[method, l1, l2][1,q] += tmp[t][1][q]/float(T)\n",
    "#         results_FR_nodeg[method, l1, l2][2,q] += tmp[t][2][q]/float(T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"DC\"-Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method = 'DC'\n",
    "# tmp = {}\n",
    "# T = 1\n",
    "# l1 = 1\n",
    "# l2 = 2\n",
    "# results_DC = {}\n",
    "\n",
    "\n",
    "# for t in range(T):\n",
    "#     tmp[t] = perform_analysis(G, H, 0.1, TT = 0)\n",
    "\n",
    "# results_DC[method, l1, l2] = np.zeros((3,len(tmp[0][0])))\n",
    "# for t in tmp:\n",
    "#     for q in range(len(tmp[t][0])):\n",
    "#         results_DC[method, l1, l2][0,q] += tmp[t][0][q]/float(T)\n",
    "#         results_DC[method, l1, l2][1,q] += tmp[t][1][q]/float(T)\n",
    "#         results_DC[method, l1, l2][2,q] += tmp[t][2][q]/float(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logreg.pkl\", \"wb\") as _fh:\n",
    "    pickle.dump([remnants, models, model_performances], _fh, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(\"logreg-fr.pkl\", \"wb\") as _fh:\n",
    "#     pickle.dump(results_FR, _fh, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(\"logreg-fr-nodeg.pkl\", \"wb\") as _fh:\n",
    "# #     pickle.dump(results_FR_nodeg, _fh, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(\"dc.pkl\", \"wb\") as _fh:\n",
    "#     pickle.dump(results_DC, _fh, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"many-walks_logreg.pkl\", \"rb\") as _fh:\n",
    "    results_logreg = pickle.load(_fh)[-1]\n",
    "# with open(\"logreg-fr.pkl\", \"rb\") as _fh:\n",
    "#     results_FR = pickle.load(_fh)[('node2vec', 1, 2)]\n",
    "# with open(\"logreg-fr-nodeg.pkl\", \"rb\") as _fh:\n",
    "#     results_FR_nodeg = pickle.load(_fh)[('node2vec', 1, 2)]\n",
    "with open(\"dc.pkl\", \"rb\") as _fh:\n",
    "    results_DC = pickle.load(_fh)[('DC', 1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate figure, subset relevant data\n",
    "fig = plt.figure()\n",
    "\n",
    "# Plotting data\n",
    "X = sorted(results_logreg.keys())\n",
    "Y = [perfs[\"auroc\"] for perfs in results_logreg.values()]\n",
    "plt.plot(\n",
    "    X, Y,\n",
    "    label=\"LogReg-classifier\",\n",
    "    color=\"red\",\n",
    "    marker=\"^\"\n",
    ")\n",
    "# plt.plot(\n",
    "#     results_FR[0], results_FR[-1],\n",
    "#     label=\"LogReg-FR-classifier\",\n",
    "#     color=\"orange\",\n",
    "#     marker=\"v\",\n",
    "#     linestyle=\"-.\"\n",
    "# )\n",
    "# plt.plot(\n",
    "#     results_FR_nodeg[0], results_FR_nodeg[-1],\n",
    "#     label=\"LogReg-FR-nodeg-classifier\",\n",
    "#     color=\"green\",\n",
    "#     marker=\"x\",\n",
    "#     linestyle=\":\"\n",
    "# )\n",
    "plt.plot(\n",
    "    results_DC[0], results_DC[-1],\n",
    "    label=\"\\\"DC\\\"-classifier\",\n",
    "    color=\"blue\",\n",
    "    marker=\"o\",\n",
    "    linestyle=\"--\"\n",
    ")\n",
    "\n",
    "plt.hlines(0.5, 0, 1, linestyles=\":\", color=\"gray\", alpha=0.5)\n",
    "\n",
    "# Axes configuration\n",
    "ax = fig.axes[0]\n",
    "\n",
    "plt.xticks(np.linspace(0, 1, 11))\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "\n",
    "plt.xlabel(\"$\\\\theta$\")\n",
    "plt.ylabel(\"ROC-AUC\")\n",
    "\n",
    "# Figure-level attributes\n",
    "plt.legend(title=\"Reconstruction\", loc=\"lower right\", bbox_to_anchor=(0.95, 0.25))\n",
    "plt.title(\"Examining size effect with Embeddings\\n Walk length = 20\")\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(f\"{_FIGS}/line_auroc-pfi_hue-method_walklength-20_EMBex35.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate figure, subset relevant data\n",
    "# fig = plt.figure()\n",
    "\n",
    "# # Plotting data\n",
    "# # plt.plot(\n",
    "# #     results_FR_nodeg[0], results_FR_nodeg[-1],\n",
    "# #     label=\"LogReg-FR-nodeg-classifier\",\n",
    "# #     color=\"red\",\n",
    "# #     marker=\"^\",\n",
    "# #     linestyle=\"-.\"\n",
    "# # )\n",
    "# plt.plot(\n",
    "#     results_FR[0], results_FR[-1],\n",
    "#     label=\"LogReg-FR-classifier\",\n",
    "#     color=\"orange\",\n",
    "#     marker=\"v\",\n",
    "#     linestyle=\"-.\"\n",
    "# )\n",
    "# plt.plot(\n",
    "#     results_DC[0][1:], results_DC[-1][1:],\n",
    "#     label=\"\\\"DC\\\"-classifier\",\n",
    "#     color=\"blue\",\n",
    "#     marker=\"o\",\n",
    "#     linestyle=\"--\"\n",
    "# )\n",
    "\n",
    "# # plt.hlines(0.5, 0.05, 0.95, linestyles=\":\", color=\"gray\", alpha=0.5)\n",
    "\n",
    "# # Axes configuration\n",
    "# ax = fig.axes[0]\n",
    "\n",
    "# plt.xticks(np.linspace(0.1, 0.9, 9))\n",
    "# ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "\n",
    "# plt.xlabel(\"$\\\\theta$\")\n",
    "# plt.ylabel(\"ROC-AUC\")\n",
    "\n",
    "# # Figure-level attributes\n",
    "# plt.legend(title=\"Reconstruction\", loc=\"lower right\")\n",
    "# plt.title(\"Examining size effect with Embeddings\")\n",
    "\n",
    "# # plt.fill_between(results_DC[0][1:7], results_DC[-1][1:7], results_FR[-1][:6], color=\"gray\", alpha=0.15)\n",
    "# # plt.fill_between(results_DC[0][-4:], results_DC[-1][-4:], results_FR[-1][-4:], color=\"red\", alpha=0.1)\n",
    "\n",
    "# # Save plot\n",
    "# # plt.savefig(f\"{_FIGS}/line_auroc-pfi_hue-method_EMBex35.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenced figures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <center>\n",
    "    <img src=\"../../results/plots/line_auroc-theta_hue-features_gamma-2.1_compare-DC_EMB_ex33v2.1_DK_20230417.png\" alt=\"ex33v2.1_comparison-fig\" class=\"bg-primary\" style=\"width:50%\">\n",
    "    <figcaption><a id='ref-fig-1'>Reference Figure (1)</a>: EMB_ex33v2.1 results compared with prior results. </figcaption>\n",
    "    </center>\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <center>\n",
    "    <img src=\"../../results/plots/line_auroc-pfi_hue-size_style-method_EMBex34.png\" alt=\"ex34_annotated-fig\" class=\"bg-primary\" style=\"width:50%\">\n",
    "    <figcaption><a id='ref-fig-1'>Reference Figure (2)</a>: EMB_ex34 results show casing effect of network size on reconstruction. </figcaption>\n",
    "    </center>\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Extra in case HTML does not render in pandoc export](\"../../results/plots/line_auroc-theta_hue-features_gamma-2.1_compare-DC_EMB_ex33v2.1_DK_20230417.png\") -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmbeddedNaive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
