{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "sys.path.append(\"../../src/\")\n",
    "from src.data.caches import CachedEmbeddings\n",
    "from src.embed import helpers\n",
    "from src.classifiers import logreg as lr\n",
    "from src.classifiers import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGREG = {\n",
    "    \"penalty\": \"none\",\n",
    "    \"solver\": \"newton-cg\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once-thru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/input/caches/method-LE_percomponent-False_dim-128_embrep-0_remnants_theta-0.05_strategy-RANDOM_remrep-1_edgelists_name-LFR_N-10000_T1-2.1_T2-1.0_kavg-20.0-kmax-100_mu-0.1_prob-1.0_rep-1.pkl\", \"rb\") as _fh:\n",
    "    cache = pickle.load(_fh)\n",
    "with open(\"../../data/input/data_input_manuscript_initial/edgelists_name-LFR_N-10000_T1-2.1_T2-1.0_kavg-20.0-kmax-100_mu-0.1_prob-1.0_rep-1.pkl\", \"rb\") as _fh:\n",
    "    mplx = pickle.load(_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_observed_edges = {}\n",
    "for edge in cache.observed_edges:\n",
    "    if mplx[0].has_edge(*edge):\n",
    "        fixed_observed_edges[edge] = 1\n",
    "    else:\n",
    "        fixed_observed_edges[edge] = 0\n",
    "\n",
    "fixed_unobserved_edges = {}\n",
    "for edge in cache.unobserved_edges:\n",
    "    if mplx[0].has_edge(*edge):\n",
    "        fixed_unobserved_edges[edge] = 1\n",
    "    else:\n",
    "        fixed_unobserved_edges[edge] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_features(cache, observed_edges):\n",
    "    # Get training labels\n",
    "    Y = features.get_labels(observed_edges)\n",
    "\n",
    "    # Degree feature\n",
    "    src_G, tgt_G = features.get_degrees(cache.remnants[0].remnant, observed_edges)\n",
    "    src_H, tgt_H = features.get_degrees(cache.remnants[1].remnant, observed_edges)\n",
    "    degree_products_G = src_G * tgt_G\n",
    "    degree_products_H = src_H * tgt_H\n",
    "    X_degrees = features.as_configuration(degree_products_G, degree_products_H)\n",
    "\n",
    "    # Distances feature\n",
    "    distances_G = features.get_distances(cache.embeddings[0].vectors, observed_edges)\n",
    "    distances_H = features.get_distances(cache.embeddings[1].vectors, observed_edges)\n",
    "    X_distances = features.as_configuration(distances_G, distances_H)\n",
    "\n",
    "    # Feature matrix\n",
    "    X = features.format_feature_matrix((X_degrees, X_distances))\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def get_testing_features(cache, unobserved_edges):\n",
    "    # Get testing labels\n",
    "    Y = features.get_labels(unobserved_edges)\n",
    "\n",
    "    # Degree feature\n",
    "    src_G, tgt_G = features.get_degrees(cache.remnants[0].remnant, unobserved_edges)\n",
    "    src_H, tgt_H = features.get_degrees(cache.remnants[1].remnant, unobserved_edges)\n",
    "    degree_products_G = src_G * tgt_G\n",
    "    degree_products_H = src_H * tgt_H\n",
    "    X_degrees = features.as_configuration(degree_products_G, degree_products_H)\n",
    "\n",
    "    # Distances feature\n",
    "    distances_G = features.get_distances(cache.embeddings[0].vectors, unobserved_edges)\n",
    "    distances_H = features.get_distances(cache.embeddings[1].vectors, unobserved_edges)\n",
    "    X_distances = features.as_configuration(distances_G, distances_H)\n",
    "\n",
    "    # Feature matrix\n",
    "    X = features.format_feature_matrix((X_degrees, X_distances))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_training_features(cache, fixed_observed_edges)\n",
    "X_test, Y_test = get_testing_features(cache, fixed_unobserved_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.LogReg(\"LogReg\", (\"deg\", \"emb\"), dict(), X_train, Y_train, LOGREG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6895269156463264\n"
     ]
    }
   ],
   "source": [
    "print(model.testing_performance(X_test, Y_test, \"AUROC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(cache_fp):\n",
    "    # Get caches\n",
    "    with open(cache_fp, 'rb') as _fh:\n",
    "        cache = pickle.load(_fh)\n",
    "\n",
    "    # Get original edgelists\n",
    "    edgelists_fp = f\"../../data/input/data_input_manuscript_initial/edgelists{cache_fp.split('edgelists')[1]}\"\n",
    "    with open(edgelists_fp, 'rb') as _fh:\n",
    "        edgelists = pickle.load(_fh)\n",
    "\n",
    "    # Fix edge labels\n",
    "    ## Training edges\n",
    "    fixed_observed_edges = {}\n",
    "    for edge in cache.observed_edges:\n",
    "        if edgelists[0].has_edge(*edge):\n",
    "            fixed_observed_edges[edge] = 1\n",
    "        else:\n",
    "            fixed_observed_edges[edge] = 0\n",
    "    cache.observed_edges = fixed_observed_edges\n",
    "\n",
    "    ## Testing edges\n",
    "    fixed_unobserved_edges = {}\n",
    "    for edge in cache.unobserved_edges:\n",
    "        if edgelists[0].has_edge(*edge):\n",
    "            fixed_unobserved_edges[edge] = 1\n",
    "        else:\n",
    "            fixed_unobserved_edges[edge] = 0\n",
    "    cache.unobserved_edges = fixed_unobserved_edges\n",
    "\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_features(cache, observed_edges):\n",
    "    # Get training labels\n",
    "    Y = features.get_labels(observed_edges)\n",
    "\n",
    "    # Degree feature\n",
    "    src_G, tgt_G = features.get_degrees(cache.remnants[0].remnant, observed_edges)\n",
    "    src_H, tgt_H = features.get_degrees(cache.remnants[1].remnant, observed_edges)\n",
    "    degree_products_G = src_G * tgt_G\n",
    "    degree_products_H = src_H * tgt_H\n",
    "    X_degrees = features.as_configuration(degree_products_G, degree_products_H)\n",
    "\n",
    "    # Distances feature\n",
    "    distances_G = features.get_distances(cache.embeddings[0].vectors, observed_edges)\n",
    "    distances_H = features.get_distances(cache.embeddings[1].vectors, observed_edges)\n",
    "    X_distances = features.as_configuration(distances_G, distances_H)\n",
    "\n",
    "    # Feature matrix\n",
    "    X = features.format_feature_matrix((X_degrees, X_distances))\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def get_testing_features(cache, unobserved_edges):\n",
    "    # Get testing labels\n",
    "    Y = features.get_labels(unobserved_edges)\n",
    "\n",
    "    # Degree feature\n",
    "    src_G, tgt_G = features.get_degrees(cache.remnants[0].remnant, unobserved_edges)\n",
    "    src_H, tgt_H = features.get_degrees(cache.remnants[1].remnant, unobserved_edges)\n",
    "    degree_products_G = src_G * tgt_G\n",
    "    degree_products_H = src_H * tgt_H\n",
    "    X_degrees = features.as_configuration(degree_products_G, degree_products_H)\n",
    "\n",
    "    # Distances feature\n",
    "    distances_G = features.get_distances(cache.embeddings[0].vectors, unobserved_edges)\n",
    "    distances_H = features.get_distances(cache.embeddings[1].vectors, unobserved_edges)\n",
    "    X_distances = features.as_configuration(distances_G, distances_H)\n",
    "\n",
    "    # Feature matrix\n",
    "    X = features.format_feature_matrix((X_degrees, X_distances))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(cache):\n",
    "    # Set up features\n",
    "    cache.embeddings[0].normalize(helpers.get_components(cache.remnants[0].remnant))\n",
    "    cache.embeddings[1].normalize(helpers.get_components(cache.remnants[1].remnant))\n",
    "    X_train, Y_train = get_training_features(cache, cache.observed_edges)\n",
    "    X_test, Y_test = get_testing_features(cache, cache.unobserved_edges)\n",
    "\n",
    "    # Train model\n",
    "    model = lr.LogReg(\"LogReg\", (\"deg\", \"emb\"), dict(), X_train, Y_train, LOGREG)\n",
    "\n",
    "    # Evaluate reconstruction(s)\n",
    "    acc = model.testing_performance(X_test, Y_test, \"ACC\")\n",
    "    auroc = model.testing_performance(X_test, Y_test, \"AUROC\")\n",
    "    pr = model.testing_performance(X_test, Y_test, \"PR\")\n",
    "\n",
    "    # Form output record\n",
    "    record = {\n",
    "        \"accuracy\": acc,\n",
    "        \"auroc\": auroc,\n",
    "        \"pr\": pr\n",
    "    }\n",
    "\n",
    "    # Return\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis():\n",
    "    records = []\n",
    "    for cache_fp in tqdm(os.listdir(\"../../data/input/caches/\")):\n",
    "        # Bring cache into scope\n",
    "        # print(cache_fp)\n",
    "        cache_fp = \"../../data/input/caches/\" + cache_fp\n",
    "        cache = get_data(cache_fp)\n",
    "\n",
    "        # Evaluate cache\n",
    "        record = evaluate(cache)\n",
    "\n",
    "        # Append parameter information\n",
    "        record.update({\n",
    "            \"method\": cache_fp.split(\"method\")[1].split(\"_\")[0][1:],\n",
    "            \"theta\": cache_fp.split(\"theta\")[1].split(\"_\")[0][1:],\n",
    "            \"mu\": cache_fp.split(\"mu\")[1].split(\"_\")[0][1:],\n",
    "        })\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    # Save to disk\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df.to_csv(\"../../data/output/dataframes/dataframe_EMB_exSYSLFR_normalized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005366325378417969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 57,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935cb3434431410ab57f1564aec73465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate prior manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmbeddedNaive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
